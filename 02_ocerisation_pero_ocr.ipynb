{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed2d7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pero-ocr\n",
    "#O Kodym, M Hradiš: Page Layout Analysis System for Unconstrained Historic Documents. ICDAR, 2021.\n",
    "#M Kišš, K Beneš, M Hradiš: AT-ST: Self-Training Adaptation Strategy for OCR in Domains with Limited Transcriptions. ICDAR, 2021.\n",
    "#J Kohút, M Hradiš: TS-Net: OCR Trained to Switch Between Text Transcription Styles. ICDAR, 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f285734",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mailan/anaconda3/envs/Mémoire/lib/python3.9/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.25.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/home/mailan/anaconda3/envs/Mémoire/lib/python3.9/site-packages/numba/__init__.py\", line 42, in <module>\n",
      "    from numba.np.ufunc import (vectorize, guvectorize, threading_layer,\n",
      "  File \"/home/mailan/anaconda3/envs/Mémoire/lib/python3.9/site-packages/numba/np/ufunc/__init__.py\", line 3, in <module>\n",
      "    from numba.np.ufunc.decorators import Vectorize, GUVectorize, vectorize, guvectorize\n",
      "  File \"/home/mailan/anaconda3/envs/Mémoire/lib/python3.9/site-packages/numba/np/ufunc/decorators.py\", line 3, in <module>\n",
      "    from numba.np.ufunc import _internal\n",
      "SystemError: initialization of _internal failed without raising an exception\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot import numba, creating dummy jit definition\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import configparser\n",
    "import cv2\n",
    "import numpy as np\n",
    "from lxml import etree\n",
    "from pero_ocr.document_ocr.layout import PageLayout\n",
    "from pero_ocr.document_ocr.page_parser import PageParser\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2785159f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Pero-OCR\n",
    "\n",
    "path=\"./Annonces_Lyon\"\n",
    "\n",
    "os.chdir(path)\n",
    "for subdir,dirs,files in os.walk(path, topdown=True):\n",
    "    for file in files:\n",
    "        if file.endswith(\".jpg\") or file.endswith(\".tif\"):\n",
    "            path_file=os.path.join(path, subdir)\n",
    "            os.chdir(path_file)\n",
    "            \n",
    "            # configuration\n",
    "            config_path = \"./pero-ocr-modele/config.ini\"\n",
    "            config = configparser.ConfigParser()\n",
    "            config.read(config_path)\n",
    "            page_parser = PageParser(config, config_path=os.path.dirname(config_path))\n",
    "            input_image_path = os.path.join(path_file, file)\n",
    "            \n",
    "            # lecture de l'image\n",
    "            image = cv2.imread(input_image_path, 1)\n",
    "            page_layout = PageLayout(id=input_image_path,page_size=(image.shape[0], image.shape[1]))\n",
    "            \n",
    "            # océrisation\n",
    "            page_layout = page_parser.process_page(image, page_layout)\n",
    "            \n",
    "            # création d'un nouveau dossier pour stocker les résultats de l'OCR\n",
    "            path_resultats=\"./OCR_Annonces\"\n",
    "            os.chdir(path_resultats)\n",
    "            nom_dossier_resultats=\"OCR_\"+os.path.splitext(os.path.basename(path_file))[0]\n",
    "            if not os.path.exists(nom_dossier_resultats):\n",
    "                os.mkdir(nom_dossier_resultats)\n",
    "            new_path_resultats=os.path.join(path_resultats, nom_dossier_resultats)\n",
    "            os.chdir(new_path_resultats)\n",
    "            nom_fichier='OCR_'+os.path.splitext(os.path.basename(file))[0]+'.xml'\n",
    "            \n",
    "            # enregistrement du fichier XML\n",
    "            page_layout.to_pagexml(nom_fichier)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97f0a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraire le text brut à partir des xml\n",
    "\n",
    "path = './OCR_Annonces_Lyon'\n",
    "os.chdir(path)\n",
    "for dossier_année in os.listdir(path):\n",
    "    new_path=os.path.join(path, dossier_année)\n",
    "    os.chdir(new_path)\n",
    "    for dossier_date in os.listdir(new_path):\n",
    "        newer_path=os.path.join(new_path,dossier_date)\n",
    "        os.chdir(newer_path)\n",
    "        for fichier in os.scandir(newer_path):\n",
    "            file_path = os.path.join(new_path, fichier)\n",
    "            tree = etree.parse(file_path)\n",
    "            file_name=os.path.splitext(os.path.basename(fichier))[0]+'.txt'\n",
    "            with open(file_name, 'w') as fichier_texte:\n",
    "                for elt in tree.iter('{http://schema.primaresearch.org/PAGE/gts/pagecontent/2019-07-15}Unicode'):\n",
    "                    try: fichier_texte.write(elt.text+'\\n')\n",
    "                    except:\n",
    "                        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4826e4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concaténer tous les .txt par numéro\n",
    "\n",
    "from natsort import natsorted\n",
    "\n",
    "path = './OCR_Annonces_Lyon'\n",
    "os.chdir(path)\n",
    "for dossier_année in os.listdir(path):\n",
    "    new_path=os.path.join(path, dossier_année)\n",
    "    os.chdir(new_path)\n",
    "    for dossier_date in os.listdir(new_path):\n",
    "        newer_path=os.path.join(new_path,dossier_date)\n",
    "        os.chdir(newer_path)\n",
    "\n",
    "        new_file_name=\"FULL_\"+os.path.basename(dossier_date)+\".txt\"\n",
    "\n",
    "        with open(new_file_name, \"w\") as new_file:\n",
    "            for name in natsorted(os.listdir(newer_path)):\n",
    "                if name.endswith(\".txt\"):\n",
    "                    with open(name) as f:\n",
    "                        for line in f:\n",
    "                            new_file.write(line)\n",
    "                        new_file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec6321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraire les FULL_[...].txt dans un nouveau dossier séparé\n",
    "\n",
    "path = './OCR_Annonces_Lyon'\n",
    "\n",
    "for dossier_année in os.listdir(path):\n",
    "    new_path=os.path.join(path,dossier_année)\n",
    "    os.chdir(new_path)\n",
    "    for dossier_date in os.listdir(new_path):\n",
    "        newer_path=os.path.join(new_path,dossier_date)\n",
    "        os.chdir(newer_path)\n",
    "        for fichier in os.listdir(newer_path):\n",
    "            if fichier.startswith(\"FULL\"):\n",
    "                final_path=os.path.join(path,\"FULL_\"+(os.path.basename(dossier_année)))\n",
    "                if not os.path.exists(final_path):\n",
    "                    os.mkdir(final_path)\n",
    "                shutil.move(fichier, final_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
